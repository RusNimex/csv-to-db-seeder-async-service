# CSV Import Workers

Go-воркеры для обработки задач импорта CSV данных в базу данных. Функциональность изначально была создана на PHP в `CompanyRepository` и загружалось синхронно. Это занимало значительное время (1-180 сек). Go-воркер может делать ту же работу, но гораздо быстрее (0,03-3 сек).

## Описание

Воркеры получают задачи из очереди [RabbitMQ](../../infra/rabbitmq/definitions.json) и обрабатывают импорт данных компаний в MySQL базу данных. Реализуют ту же логику, что и PHP `CompanyRepository`:

- Предзагрузка справочников (регионы, районы, города, категории, подкатегории)
- Батч-вставка geo записей
- Батч-вставка компаний
- Обработка связей (company_geo, company_category, company_subcategory)
- Оптимизация через отключение проверки внешних ключей

## Структура проекта

```
services/workers/
├── main.go          # Точка входа, инициализация и запуск воркера
├── config.go        # Загрузка конфигурации из переменных окружения
├── models.go        # Модели данных (GisCompany, ImportTask, Summary)
├── repository.go    # Логика работы с БД (аналог CompanyRepository)
├── worker.go        # Обработка задач из RabbitMQ
├── Dockerfile       # Образ для сборки воркера
├── go.mod           # Зависимости Go
└── README.md        # Документация
```

## Переменные окружения

- `DB_HOST` - хост MySQL (по умолчанию: `mysql`)
- `DB_PORT` - порт MySQL (по умолчанию: `3306`)
- `DB_NAME` - имя базы данных (по умолчанию: `csv`)
- `DB_USER` - пользователь БД (по умолчанию: `csv_user`)
- `DB_PASSWORD` - пароль БД (по умолчанию: `csv_pass`)
- `RABBITMQ_URL` - URL подключения к RabbitMQ (обязательно)
- `STORAGE_PATH` - путь к директории storage (по умолчанию: `/app/storage`)
- `WORKER_QUEUES` - очереди для обработки через запятую (по умолчанию: все очереди)
- `WORKER_BATCH_SIZE` - размер батча для обработки (по умолчанию: `2000`)
- `WORKER_PREFETCH_COUNT` - количество предзагружаемых сообщений (по умолчанию: `1`)

## Формат задачи

Воркер ожидает задачи в формате JSON от API:

```json
{
  "file_path": "/var/www/html/storage/csv/csv_1234567890_file.csv",
  "file_name": "file.csv",
  "file_size": 102400,
  "priority": "normal",
  "created_at": "2024-01-01 12:00:00"
}
```

Воркер:
1. Читает CSV файл по указанному пути
2. Парсит CSV с разделителем `;`
3. Обрабатывает записи и импортирует в БД
4. Удаляет обработанный файл

## Очереди

Воркер обрабатывает следующие очереди:
- `csv_import_high` - высокоприоритетные задачи (файлы < 1MB)
- `csv_import_normal` - обычные задачи (1MB - 50MB)
- `csv_import_large` - большие файлы (> 50MB)

По умолчанию воркер обрабатывает все очереди. Можно указать конкретные очереди через переменную окружения `WORKER_QUEUES` (через запятую).

## Сборка и запуск

### Production (через docker-compose)

```bash
cd infra
docker-compose up -d worker

# Пересборка в разработке
docker-compose up -d --build worker

# Просмотр логов после пересборки
docker-compose logs -f worker
```

Воркер использует собранный бинарник из образа.

### Development (с hot reload)

```bash
cd infra
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up worker
```

В dev режиме:
- Используется `Dockerfile.dev` с golang образом
- Код монтируется через volume для hot reload
- Запускается через `go run .` (перезапустите контейнер при изменении кода)

### Локальная разработка (без Docker)

```bash
# Установка зависимостей
go mod download

# Запуск
go run .
```

## Интеграция с docker-compose

### Production
- Использует `Dockerfile` (alpine образ с бинарником)
- Бинарник находится в `/usr/local/bin/worker`
- Volume только для storage

### Development
- Использует `Dockerfile.dev` (golang образ)
- Volume для кода (`../services/workers:/app`)
- Запускается через `go run .`

## Особенности реализации

1. **Батч-обработка**: Данные обрабатываются батчами для оптимизации производительности
2. **Кэширование**: Справочники кэшируются в памяти для быстрого доступа
3. **Транзакции**: Все операции выполняются в транзакциях для обеспечения целостности данных
4. **Graceful shutdown**: Воркер корректно завершает работу при получении сигналов SIGTERM/SIGINT
5. **Обработка ошибок**: Ошибки логируются, но не прерывают обработку других записей

## Производительность

- Размер батча для pivot таблиц: 5000 записей
- Размер батча для обработки: настраивается через `WORKER_BATCH_SIZE`
- Prefetch count: настраивается через `WORKER_PREFETCH_COUNT`

## Логирование

Воркер выводит логи в stdout:
- Подключение к БД и RabbitMQ
- Получение задач
- Статистика импорта
- Ошибки обработки

